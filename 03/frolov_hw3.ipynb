{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 30 апреля 2018, 06:00   \n",
    "**Штраф за опоздание:** -2 балла после 06:00 30 апреля, -4 балла после 06:00 7 мая, -6 баллов после 06:00 14 мая, -8 баллов после 06:00 21 мая\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext pycodestyle_magic\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from IPython.core.magic import (register_line_magic,\n",
    "                                register_cell_magic)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_line_magic\n",
    "def xtime(line):\n",
    "    t = time()\n",
    "    r = get_ipython().ev(line)\n",
    "    t = time() - t\n",
    "    print(f'Done in {t:.3f} sec: {line}')\n",
    "    return r\n",
    "\n",
    "@register_cell_magic\n",
    "def xtime(line, cell):\n",
    "    t = time()\n",
    "    get_ipython().run_cell(cell)\n",
    "    t = time() - t\n",
    "    if line:\n",
    "        print(f'Done in {t:.3f} sec: {line}')\n",
    "    else:\n",
    "        print(f'Done in {t:.3f} sec')\n",
    "\n",
    "@register_cell_magic\n",
    "def xcodestyle(line, cell):\n",
    "    ipython = get_ipython()\n",
    "    ipython.run_cell_magic('pycodestyle', line, cell)\n",
    "    ipython.run_cell(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from numba import autojit\n",
    "except:\n",
    "    def autojit(func):\n",
    "        return func\n",
    "\n",
    "@autojit\n",
    "def get_class_count(y, cut_size=0):\n",
    "    classes = np.unique(y)\n",
    "    l_c = np.zeros(shape=(classes.size, y.size), dtype=int)\n",
    "    for i, c in enumerate(classes):\n",
    "        l_c[i] = np.cumsum(y==c)\n",
    "    r_c = l_c[:, -1:] - l_c[:, :-1]\n",
    "    s = np.arange(1, y.size, dtype=int)\n",
    "    \n",
    "    l_c, l_s, r_c, r_s =  l_c[:, :-1], s, r_c, s[::-1]\n",
    "        \n",
    "    if cut_size:\n",
    "        l_c = l_c[:, cut_size: -cut_size]\n",
    "        l_s = l_s[cut_size: -cut_size]\n",
    "        r_c = r_c[:, cut_size: -cut_size]\n",
    "        r_s = r_s[cut_size: -cut_size]\n",
    "    return l_c, l_s, r_c, r_s\n",
    "\n",
    "@autojit\n",
    "def get_class_count2(y, cut_size=0):\n",
    "    if cut_size == 0:\n",
    "        splitted = y\n",
    "    else:\n",
    "        splitted = y[cut_size:-cut_size]\n",
    "    r_border_ids = np.where(splitted[:-1] !=\n",
    "                            splitted[1:])[0] + (cut_size + 1)\n",
    "\n",
    "    if len(r_border_ids) == 0:\n",
    "        return call(), np.inf, None\n",
    "\n",
    "    class_number = np.max(y) + 1\n",
    "    eq_el_count = r_border_ids - np.append(np.array([cut_size]),\n",
    "                                           r_border_ids[:-1])\n",
    "    one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "    one_hot_code[np.arange(r_border_ids.shape[0]),\n",
    "                 y[r_border_ids - 1]] = 1\n",
    "    class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "    class_increments[0] = class_increments[0] + \\\n",
    "        np.bincount(y[:cut_size], minlength=class_number)\n",
    "\n",
    "    l_c = np.cumsum(class_increments, axis=0)\n",
    "    r_c = np.bincount(y, minlength=class_number) - l_c\n",
    "    l_s = r_border_ids.reshape(l_c.shape[0], 1)\n",
    "    r_s = y.shape[0] - l_s\n",
    "    return l_c.T, l_s.flatten(), r_c.T, r_s.flatten()\n",
    "\n",
    "def get_class_count_slow(y, cut_size=0):\n",
    "    classes = np.unique(y)\n",
    "    l_c = np.zeros(shape=(classes.size, y.size), dtype=int)\n",
    "    for i, c in enumerate(classes):\n",
    "        l_c[i] = np.cumsum(y==c)\n",
    "    r_c = l_c[:, -1:] - l_c[:, :-1]\n",
    "    s = np.arange(1, y.size, dtype=int)\n",
    "    \n",
    "    l_c, l_s, r_c, r_s =  l_c[:, :-1], s, r_c, s[::-1]\n",
    "        \n",
    "    if cut_n:\n",
    "        l_c = l_c[:, cut_size: -cut_size]\n",
    "        l_s = l_s[cut_size: -cut_size]\n",
    "        r_c = r_c[:, cut_size: -cut_size]\n",
    "        r_s = r_s[cut_size: -cut_size]\n",
    "    return l_c, l_s, r_c, r_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%xcodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None,\n",
    "                 sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "            self.G_function_y = self.__gini_y\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "            self.G_function_y = self.__entropy_y\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "            self.G_function_y = self.__misclass_y\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features is None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        # Ваш код\n",
    "        return 1 - np.sum(l_c**2/l_s + r_c**2/r_s, 0) / (l_s+r_s)\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        # Ваш код\n",
    "        return -np.sum(l_c * np.log2(l_c/l_s)\n",
    "                       + r_c * np.log2(r_c/r_s), 0) / (l_s+r_s)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        # Ваш код\n",
    "        return 1 - (np.max(l_c, 0) + np.max(r_c, 0)) / (l_s+r_s)\n",
    "\n",
    "    def __gini_y(self, y_c, y_s):\n",
    "        return y_s - np.sum(y_c**2) / y_s\n",
    "\n",
    "    def __entropy_y(self, y_c, y_s):\n",
    "        return -np.sum(y_c * np.log2(y_c/y_s)) / (y_s)\n",
    "\n",
    "    def __misclass_y(self, y_c, y_s):\n",
    "        return y_s - np.max(y_c) / y_s\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        # Ваш код\n",
    "        return feature_ids[:np.sqrt(n_feature)]\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        # Ваш код\n",
    "        return feature_ids[:np.log2(n_feature)]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        # Ваш код\n",
    "        return np.arange(n_feature)\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __add_leaf(self, node_id, y):\n",
    "        self.tree[node_id] = (self.LEAF_TYPE,\n",
    "                              np.bincount(y).argmax(),\n",
    "                              np.bincount(y) / y.size)\n",
    "        return\n",
    "\n",
    "    def __add_node(self, node_id, feature_id, threshold):\n",
    "        self.tree[node_id] = (self.NON_LEAF_TYPE, feature_id, threshold)\n",
    "        return\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Ваш код\n",
    "        x_sort, y_sort = self.__sort_samples(x, y)\n",
    "\n",
    "        cut_n = self.min_samples_split // 2 - 1\n",
    "        l_c, l_s, r_c, r_s = get_class_count2(y_sort, cut_n)\n",
    "\n",
    "        G = self.G_function_y(l_c[:, 0] + r_c[:, 0], y.size)\n",
    "        Gs = self.G_function(l_c, l_s, r_c, r_s)\n",
    "\n",
    "        idx = np.argmin(Gs)\n",
    "        x_idx = l_s[idx]\n",
    "\n",
    "        res = Gs[idx], G, (x_sort[x_idx-1] + x_sort[x_idx])/2\n",
    "        return res\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        # Ваш код\n",
    "        if ((self.max_depth is not None and self.max_depth < depth)\n",
    "                or (y.size < self.min_samples_split)\n",
    "                or (np.unique(y).size == 1)\n",
    "                or (np.bincount(y).argmax() > y.size * self.sufficient_share)):\n",
    "            self.__add_leaf(node_id, y)\n",
    "            return\n",
    "\n",
    "        feature_ids = self.get_feature_ids(x.shape[1])\n",
    "        thresholds = np.array([self.__find_threshold(x[:, feature_id], y)\n",
    "                               for feature_id in feature_ids])\n",
    "\n",
    "        best_feature = feature_ids[np.argmin(thresholds[:, 0])]\n",
    "        neg_gain, pos_gain, threshold = thresholds[np.argmin(thresholds[:, 0])]\n",
    "\n",
    "        x_l, x_r, y_l, y_r = self.__div_samples(x, y, best_feature, threshold)\n",
    "\n",
    "        if y_l.size == 0 or y_r.size == 0:\n",
    "            self.__add_leaf(node_id, y)\n",
    "            return\n",
    "\n",
    "        self.__add_node(node_id, best_feature, threshold)\n",
    "        self.feature_importances_[best_feature] += pos_gain - neg_gain\n",
    "\n",
    "        self.__fit_node(x_l, y_l, 2 * node_id + 1, depth + 1)\n",
    "        self.__fit_node(x_r, y_r, 2 * node_id + 2, depth + 1)\n",
    "        return\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        self.feature_importances_ /= np.sum(self.feature_importances_)\n",
    "        return self\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0.002 sec: clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%xtime clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0.034 sec: my_clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.MyDecisionTreeClassifier at 0x7f988492f4e0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%xtime my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.890993265993266"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.890993265993266"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./speed-dating-experiment/Speed Dating Data.csv', encoding='latin1')\n",
    "df = df.iloc[:, :97]\n",
    "df = df.drop(['id', 'idg', 'condtn', 'round', 'position', 'positin1',\n",
    "             'order', 'partner', 'age_o', 'race_o', 'pf_o_att', \n",
    "              'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha',\n",
    "              'dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o',\n",
    "              'amb_o', 'shar_o', 'like_o', 'prob_o', 'met_o', 'undergra',\n",
    "              'from', 'zipcode', 'sports','tvsports','exercise','dining',\n",
    "              'museums','art','hiking','gaming', 'clubbing','reading','tv',\n",
    "              'theater','movies','concerts','music','shopping','yoga',\n",
    "              'expnum'], axis=1)\n",
    "df.drop_duplicates(subset=['iid']).gender.value_counts()\n",
    "df = df.dropna(subset=['age'])\n",
    "df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(19)\n",
    "df = df.drop(['field'], axis=1)\n",
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'mn_sat'] = df.mn_sat.fillna(df.mn_sat[df.mn_sat.notna()].mean())\n",
    "\n",
    "df.loc[:, 'tuition'] = df.loc[:, 'tuition'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'tuition'] = df.tuition.fillna(df.tuition[df.tuition.notna()].mean())\n",
    "\n",
    "df = df.dropna(subset=['imprelig', 'imprace'])\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].fillna(-999)\n",
    "\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(18)\n",
    "df = df.drop(['career'], axis=1)\n",
    "\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:,\n",
    "                                    ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1',\n",
    "                                     'amb1_1', 'shar1_1']].sum(axis=1)\n",
    "df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']] = \\\n",
    "    (df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']].T\n",
    "     / df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, \n",
    "                                    ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1',\n",
    "                                     'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']] = \\\n",
    "    (df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']].T\n",
    "     / df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "df = df.drop(['temp_totalsum'], axis=1)\n",
    "\n",
    "for i in [4, 5]:\n",
    "    feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i), \n",
    "            'intel{}_1'.format(i), 'fun{}_1'.format(i), \n",
    "            'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "    \n",
    "    if i != 4:\n",
    "        feat.remove('shar{}_1'.format(i))\n",
    "    \n",
    "    df = df.drop(feat, axis=1)\n",
    "df = df.drop(['wave'], axis=1)\n",
    "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid'])\\\n",
    "                                 .drop(['gender'], axis=1)\\\n",
    "                                 .dropna()\n",
    "df_female = df.query('gender == 0').drop_duplicates(subset=['iid'])\\\n",
    "                                   .drop(['gender', 'match', 'int_corr', 'samerace'], axis=1)\\\n",
    "                                   .dropna()\n",
    "        \n",
    "df_female.columns = df_female.columns + '_f'\n",
    "df_female = df_female.drop(['pid_f'], axis=1)\n",
    "df_pair = df_male.join(df_female.set_index('iid_f'),\n",
    "                       on='pid',\n",
    "                       how='inner')\n",
    "df_pair = df_pair.drop(['iid', 'pid'], axis=1)\n",
    "X = df_pair.iloc[:, 1:].values\n",
    "y = df_pair.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0.129 sec: clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%xtime clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 1.434 sec: my_clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.MyDecisionTreeClassifier at 0x7f988492fcc0>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%xtime my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5287952351069569"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5738425644967702"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_pair.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_corr      0.080906\n",
       "age_f         0.027607\n",
       "attr2_1       0.027086\n",
       "age           0.025211\n",
       "attr1_1_f     0.024801\n",
       "shar1_1_f     0.024539\n",
       "intel3_1_f    0.024479\n",
       "exphappy_f    0.023664\n",
       "amb3_1_f      0.023652\n",
       "income_f      0.023235\n",
       "dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.Series(data=clf.feature_importances_,\n",
    "          index=features).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date         0.145050\n",
       "shar1_1      0.135819\n",
       "age          0.115927\n",
       "attr3_1      0.104181\n",
       "go_out       0.048375\n",
       "amb1_1_f     0.047589\n",
       "int_corr     0.041690\n",
       "tuition_f    0.029992\n",
       "fun2_1_f     0.028648\n",
       "shar1_1_f    0.020429\n",
       "dtype: float64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(data=my_clf.feature_importances_,\n",
    "          index=features).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 15}\n",
      "0.8367091772943236\n",
      "Done in 101.945 sec\n"
     ]
    }
   ],
   "source": [
    "%%xtime\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1, n_estimators=10)\n",
    "\n",
    "param_grid = { \n",
    "    'max_depth': [1,30],\n",
    "    'min_samples_leaf': range(1,30, 2),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "CV.fit(X, y)\n",
    "print(CV.best_params_)\n",
    "print(CV.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
